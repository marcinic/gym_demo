{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gym.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "J0fAsYn51ojY",
        "colab_type": "code",
        "outputId": "fb0fa02e-c40c-484d-8775-f3f19da0a9b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.11.29)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z5R79S2yur3D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reinforcement learning is learning how to map situations to actions so as to maximize a numerical reward signal. Gym is a toolkit for developing and comparing reinforcement learning algorithms."
      ]
    },
    {
      "metadata": {
        "id": "OzTiKu-GXVJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "piRzAai84ZLO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Play one game of blackjack with random actions"
      ]
    },
    {
      "metadata": {
        "id": "QzyiPxpDXn5V",
        "colab_type": "code",
        "outputId": "5afad477-a6e3-495f-921b-2c2e0c17e11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Blackjack-v0\")\n",
        "state = env.reset()\n",
        "memory = []\n",
        "for _ in range(10):\n",
        "  action = env.action_space.sample() \n",
        "  state, reward, done, info = env.step(action)\n",
        "  memory.append((state,action,reward,done))\n",
        "  if done:\n",
        "    break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KTIjdNP03_vO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calling env.step gives us an observation, reward, a boolean indicating whether the episode has finished"
      ]
    },
    {
      "metadata": {
        "id": "bUM5dqyPyd7T",
        "colab_type": "code",
        "outputId": "9ec0468f-7cd2-44f7-c59c-fd0947daa588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "memory"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((12, 4, False), 1, 0, False),\n",
              " ((13, 4, False), 1, 0, False),\n",
              " ((13, 4, False), 0, -1.0, True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "bxMQMq9fvzHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**States**"
      ]
    },
    {
      "metadata": {
        "id": "HOrrlflt6PwG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        " The observation is a 3-tuple of: \n",
        "the players current sum,\n",
        "the dealer's one showing card (1-10 where 1 is ace),\n",
        "and whether or not the player holds a usable ace (0 or 1).\n"
      ]
    },
    {
      "metadata": {
        "id": "JawetveuwPVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Actions**"
      ]
    },
    {
      "metadata": {
        "id": "hwpeOI95wObF",
        "colab_type": "code",
        "outputId": "9d2f45f9-3782-48f4-b8e1-d7ce59509982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space\n",
        "# Stay = 0\n",
        "# Hit = 1\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "0Q2veHzdDbP-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Rewards**"
      ]
    },
    {
      "metadata": {
        "id": "0lrz56IFDcsg",
        "colab_type": "code",
        "outputId": "1545f8f7-5dd6-4e14-b5b0-aa3fb649467d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Win = 1\n",
        "# Loss = -1\n",
        "\n",
        "def compute_avg_reward(memory):\n",
        "  rewards = [r[2] for r in memory]\n",
        "  return sum(rewards)/len(memory)\n",
        "\n",
        "compute_avg_reward(memory)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "o-xZL5QUIvtR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now lets play 100 games of random blackjack. We'll keep track of our score."
      ]
    },
    {
      "metadata": {
        "id": "07uJmGPa_HsU",
        "colab_type": "code",
        "outputId": "24aaa814-da52-4101-d030-e169280e21a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Blackjack-v0\")\n",
        "state = env.reset()\n",
        "memory = []\n",
        "episodes = 100\n",
        "for e in range(episodes):\n",
        "  for _ in range(10):\n",
        "    action = env.action_space.sample() \n",
        "    state, reward, done, info = env.step(action)\n",
        "    memory.append((state,action,reward,done))\n",
        "    if done:\n",
        "      break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4-fnW8bl_qPN",
        "colab_type": "code",
        "outputId": "1bd19096-b2a7-4791-fb20-9ff0edd92233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "rewards = [r[2] for r in memory]\n",
        "sum(rewards)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-100.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "0AHXmN5EATAn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's try building a simple agent."
      ]
    },
    {
      "metadata": {
        "id": "arivCokjARY5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RuleBasedAgent():\n",
        "  \n",
        "  def __init__(self,epsilon):\n",
        "    self.epsilon = epsilon\n",
        "  \n",
        "  def act(self,state):\n",
        "    if state[0]>=17:\n",
        "      return 0\n",
        "    else:\n",
        "      return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhoJjAWyCIL1",
        "colab_type": "code",
        "outputId": "d5885da7-2608-4b6f-d1c7-77881faeb53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Blackjack-v0\")\n",
        "\n",
        "memory = []\n",
        "agent = RuleBasedAgent(.1)\n",
        "episodes = 100\n",
        "for e in range(episodes):\n",
        "  state = env.reset()\n",
        "  for _ in range(10):\n",
        "    action = agent.act(state) \n",
        "    state, reward, done, info = env.step(action)\n",
        "    memory.append((state,action,reward,done))\n",
        "    if done:\n",
        "      break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xBYgCIFYDU3U",
        "colab_type": "code",
        "outputId": "072e87ce-b4fc-4acf-f5c6-446e416d706b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "compute_avg_reward(memory)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.056962025316455694"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "574Wk0g88dWT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Other environments include Atari Video games, a physics simulator called MuJuCo, and a robot arm simulator. They also provide tools to create your own environment provide a common API. We have avoided the question of reinforcement learning algorithms themselves but if you are interested in learning more OpenAI provides a series of tutorials called spinning up: https://spinningup.openai.com/en/latest/\n",
        "\n",
        "Reinforcement Learning: An Introduction by Richard Sutton and Andrew Barto defined the discipline. They recently released a second edition versions of which are available for free online."
      ]
    }
  ]
}